# 两大学派
对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派。设样本观测集为
$$
X_{N\times p}=(X_1,X_2,\cdots,X_N)^T,X_i=(x_{i1},x_{i2},\cdots,x_{ip})
$$
即样本有N个观测，每个观测是p维随机向量，其中每个观测都由概率分布$p(X_i|\theta)$生成
## 频率学派
频率学派认为概率分布$p(X_i|\theta)$的参数$\theta$是一个客观存在的常量。对于N个观测整个样本集出现的概率$P(X|\theta)\overset{iid}{=}\prod\limits_{i=1}^Np(X_i|\theta)$。此时估计$\theta$采用极大似然估计(MLE)的方法
$$
\theta_{MLE}=\arg\max_{\theta}P(X|\theta)
$$
## 贝叶斯学派
贝叶斯学派认为概率分布$p(X_i|\theta)$的参数$\theta$不是常量，而是一个符合$\theta\sim p(\theta)$分布的随机变量，这个分布称为先验分布。于是针对N个观测的样本集，根据贝叶斯定理可得出后验概率分布
$$
p(\theta|X)=\frac{P(X|\theta)p(\theta)}{P(X)}=\frac{P(X|\theta)p(\theta)}{\int_\theta P(X|\theta)p(\theta)d\theta}
$$
为了估计参数的分布，采用最大后验估计(MAP)的方法
$$
\theta_{MAP}=\arg\max_\theta p(\theta|X)=\arg\max_\theta P(X|\theta)p(\theta)
$$
然后就可以计算后验概率分布$p(\theta|X)$。$P(X|\theta)$称为似然，即模型的分布。根据后验分布就可以进行贝叶斯估计来预测新样本
$$
P(X_{new}|X)=\int_\theta P(X_{new}|\theta)p(\theta|X)d\theta
$$
# 协方差(covariance)
## 协方差
  * 概念:协方差在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。简单来讲，协方差就是衡量两个变量相关性的变量。当协方差为正时，两个变量呈正相关关系（同增同减）；当协方差为负时，两个变量呈负相关关系（一增一减）。而协方差矩阵是将所有变量的协方差关系用矩阵的形式表现出来，通过矩阵这一工具，可以更方便地进行数学运算。
  * 数学定义：设有两个一维随机变量$X=\{x_1,x_2,...x_n\},Y=\{y_1,y_2,...y_n\}$，则X和Y的协方差为
  $$
  Cov(X,Y)={\sum\limits_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})\over n-1}
  $$
  * 性质：设$X,Y$的期望和方差分别为$E(X),Var(X)$和$E(Y),Var(Y)$
    1. $Cov(X,Y)=Cov(Y,X)$
    2. $Cov(X,X)=Var(X)$
    3. $Cov(aX,bY)=abCov(X,Y)\quad a,b为常数$
    4. $Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$
    5. 根据定义自然推导
       $$
       \begin{aligned}
       Cov(X,Y)&=E[(X-E(X))(Y-E(Y))]\\
       &=E(XY)-2E(X)(Y)+E(X)E(Y)\\
       &=E(XY)-E(X)E(Y)
       \end{aligned}
       $$
    6. 如果$X$和$Y$相互独立，则$Cov(X,Y)=0$。反之不一定成立。
    7. $Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$
    8. $Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y)$
## 协方差矩阵(covariance matrix)
  * 概念：协方差只能解决二维的问题，扩展到多维就形成了协方差矩阵的概念。协方差矩阵的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。
  * 数学定义：设矩阵$X=(X_1,X_2...X_d)$，其中$X_i$为列向量，称矩阵
    $$
    \Sigma=(\sigma_{i,j}^2)_{d\times d}=
    \begin{bmatrix}
    \sigma_{11}^2&\sigma_{12}^2&\cdots&\sigma_{1d}^2 \\
    \sigma_{21}^2&\sigma_{22}^2&\cdots&\sigma_{2d}^2 \\
    \vdots&\vdots&\ddots&\vdots \\
    \sigma_{d1}^2&\sigma_{d2}^2&\cdots&\sigma_{dd}^2 \\
    \end{bmatrix}
    $$
    为$X$的协方差矩阵，也记为$D(X)$，其中
    $$
    \sigma_{ij}^2=Cov(X_i,X_j)\qquad i,j=1,2,3\ldots,d
    $$
    写为矩阵形式
    $$
    \Sigma=E([(X-E(X))^T(X-E(X))])
    $$
  * 性质：
    1. $\Sigma^T=\Sigma$
    2. $\Sigma$为半正定矩阵
    3. 若矩阵$X$中所有n维随机变量两两相互独立，则其协方差矩阵为对角矩阵
# 高斯分布
## 一维高斯分布
设一维随机变量$X=x$服从高斯分布，则其概率密度函数为
  $$
  N(x|\mu,\sigma^2)={1\over \sqrt{2\pi\sigma^2}}\exp[-{1\over 2\sigma^2}(x-\mu)^2]
  $$
  其中，$\mu,\sigma$分别为$X$的均值和标准差
## 多维高斯分布
设d维随机变量$X=(x_1,x_2,\ldots,x_d)^T$，$x_i\in \mathbb{R}^N$，则其概率密度函数为
  $$
  N(X|\mu,\Sigma)={1\over(2\pi)^{d/2}|\Sigma|^{1/2}}\exp[-{1\over 2}(X-\mu)^T\Sigma^{-1}(X-\mu)]
  $$
  其中，$\mu$为$X$的均值向量，$\Sigma$为$X$的协方差矩阵
## 高斯分布推论
设随机变量$X\sim{N(\mu,\Sigma)},X\in\mathbb{R}^p$，随机变量$Y=AX+B,Y\in\mathbb{R}^q$，则有
  $$
  Y\sim{N(A_{q\times p}\mu+B,A\Sigma{A^T})}
  $$
# 极大似然估计(Maximum Likelihood Estimate)
  * 概念：极大似然估计，通俗理解来说，就是利用已知的样本结果信息，反推最具有最大可能（最大概率）导致这些样本结果出现的模型参数值。极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的
  * 似然函数：设有一个样本$X$符合参数为$\theta$的分布，则其似然函数为$P(X|\theta)$。这里样本$X$是确定的，参数$\theta$为变量，它描述对于不同的模型参数，出现样本$X$这种样本的概率是多少
  * 极大似然估计参数
    $$
    \hat{\theta}=\arg\max_{\theta}P(X|\theta)
    $$
    实际应用中可能会对$P(X|\theta)$取对数以简化计算，即
    $$
    \hat{\theta}=\arg\max_{\theta}\log{P(X|\theta)}
    $$
