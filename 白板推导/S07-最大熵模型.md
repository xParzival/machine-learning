# 最大熵模型
最大熵原理是统计学的一般原理，应用到分类问题就得到了最大熵模型
## 最大熵模型定义
设分类问题的训练数据集$D=\{(\boldsymbol{x}_1,y_1),\boldsymbol{x}_2,y_1),\cdots,\boldsymbol{x}_N,y_N)\}$，模型是求条件概率分布$P(Y|X)$
### 经验分布
经验分布指从已有数据可以得到的经验概率，那么根据训练数据可以得到联合概率以及边缘概率的经验分布
$$
\begin{gathered}
\widetilde{P}(X=\boldsymbol{x},Y=y)=\frac{\text{count}(X=\boldsymbol{x},Y=y)}{N}\\
\widetilde{P}(X=\boldsymbol{x})=\frac{\text{count}(X=\boldsymbol{x})}{N}
\end{gathered}
$$
### 特征函数
特征函数用来描述样本满足的某个事实。具体的讲，特征函数$f(\boldsymbol{x},y)$描述输入$\boldsymbol{x}$和输出$y$之间满足的某种关系，满足该关系则特征函数为一个实值函数，否则为0
$$
f(\boldsymbol{x},y)=
\begin{cases}
g(\boldsymbol{x},y),&\boldsymbol{x}和y满足该关系\\
0,&\text{else}
\end{cases}
$$
这个特征函数一般是人为指定的，可能是某种假设，也可能是从先验知识中得到的一些关系
### 约束条件
特征函数关于经验联合分布的期望可以由下式计算
$$
\begin{aligned}
E_{\tilde{P}}[f]&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(X=\boldsymbol{x},Y=y)f(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)f(\boldsymbol{x},y)
\end{aligned}
$$
当用一个模型$P(Y|X)$表达样本时，还可以将上述期望如下表示
$$
\begin{aligned}
E_P[f]&=\sum_\boldsymbol{x}\sum_yP(Y=y|X=\boldsymbol{x})\widetilde{P}(X=\boldsymbol{x})f(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\sum_yP(y|\boldsymbol{x})\widetilde{P}(\boldsymbol{x})f(\boldsymbol{x},y)
\end{aligned}
$$
当数据量足够并且模型优秀到获取训练集中的大部分信息时，那么这两种方式计算出的期望应该相同
$$
\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)f(\boldsymbol{x},y)=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})f(\boldsymbol{x},y)
$$
这就是模型的约束条件，由几个特征函数就有几个约束条件
### 定义
设满足约束条件的条件概率模型集合为
$$
\mathcal{C}=\{P\in\mathcal{P}|E_{\tilde{P}}[f_i]=E_P[f_i],i=1,2,\cdots\}
$$
对于条件概率$P(Y|X)$，其条件熵为
$$
H(P)=-\sum_\boldsymbol{x}\sum_y\widetilde{P}(X)P(Y|X)\log P(Y|X)
$$
在条件概率模型中，条件熵最大的的模型即为最大熵模型
## 最大熵模型的学习
最大熵模型等价于如下约束优化问题
$$
\begin{gathered}
\min_{P\in\mathcal{C}}\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\log P(y|\boldsymbol{x})\\
s.t.\quad \sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)f_i(\boldsymbol{x},y)-\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})f_i(\boldsymbol{x},y)=0\quad i=1,2,\cdots,n\\
\sum_{y}P(y|\boldsymbol{x})=1
\end{gathered}
$$
引进拉格朗日乘子$\lambda_0,\lambda_1,\cdots,\lambda_n$，定义拉格朗日函数
$$
L(P,\boldsymbol{\lambda})=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\log P(y|\boldsymbol{x})+\lambda_0\left(1-\sum_{y}P(y|\boldsymbol{x})\right)+\sum_{i=1}^n\lambda_i\left(\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)f_i(\boldsymbol{x},y)-\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})f_i(\boldsymbol{x},y)\right)
$$
根据拉格朗日乘子法，原始问题为
$$
\min_{P\in\mathcal{C}}\max_\boldsymbol{\lambda}L(P,\boldsymbol{\lambda})
$$
因为$L(P,\boldsymbol{\lambda})$是$P$的凸函数，则可转化为对偶问题
$$
\max_\boldsymbol{\lambda}\min_{P\in\mathcal{C}}L(P,\boldsymbol{\lambda})
$$
先求解$\min\limits_{P\in\mathcal{C}}L(P,\boldsymbol{\lambda})$，对其求偏导
$$
\begin{gathered}
\frac{\partial L(P,\boldsymbol{\lambda})}{\partial P(y|\boldsymbol{x})}=\widetilde{P}(\boldsymbol{x})[1+\log P(y|\boldsymbol{x})]+\lambda_0-\widetilde{P}(\boldsymbol{x})\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)=0\\
\begin{aligned}
\Rightarrow P(y|\boldsymbol{x})&=\exp\left(\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)-\frac{\lambda_0}{\widetilde{P}(\boldsymbol{x})}-1\right)\\
&=\frac{\exp\sum\limits_{i=1}^n\lambda_if_i(\boldsymbol{x},y)}{\exp\left(\frac{\lambda_0}{\widetilde{P}(\boldsymbol{x})}+1\right)}
\end{aligned}
\end{gathered}
$$
根据概率和为1的约束条件有
$$
\begin{gathered}
\sum_y\frac{\exp\sum\limits_{i=1}^n\lambda_if_i(\boldsymbol{x},y)}{\exp\left(\frac{\lambda_0}{\widetilde{P}(\boldsymbol{x})}+1\right)}=1\\
\Rightarrow \exp\left(\frac{\lambda_0}{\widetilde{P}(\boldsymbol{x})}+1\right)=\sum_y\exp\sum\limits_{i=1}^n\lambda_if_i(\boldsymbol{x},y)
\end{gathered}
$$
显然这是一个归一化因子，令
$$
Z_\lambda(\boldsymbol{x})=\sum_y\exp\sum\limits_{i=1}^n\lambda_if_i(\boldsymbol{x},y)
$$
则可求得
$$
P(y|\boldsymbol{x})=\frac{\exp\sum\limits_{i=1}^n\lambda_if_i(\boldsymbol{x},y)}{Z_\lambda(\boldsymbol{x})}
$$
将求得的$P(y|\boldsymbol{x})$带回拉格朗日函数
$$
\begin{aligned}
L(P,\boldsymbol{\lambda})&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\log P(y|\boldsymbol{x})+\sum_{i=1}^n\lambda_i\left(\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)f_i(\boldsymbol{x},y)-\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})f_i(\boldsymbol{x},y)\right)\\
&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\log P(y|\boldsymbol{x})+\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)-\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\left(\log P(y|\boldsymbol{x})-\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)\right)+\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x})P(y|\boldsymbol{x})\log Z_\lambda(\boldsymbol{x})+\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\widetilde{P}(\boldsymbol{x})\log Z_\lambda(\boldsymbol{x})\sum_yP(y|\boldsymbol{x})+\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)\\
&=\sum_\boldsymbol{x}\widetilde{P}(\boldsymbol{x})\log Z_\lambda(\boldsymbol{x})+\sum_\boldsymbol{x}\sum_y\widetilde{P}(\boldsymbol{x},y)\sum_{i=1}^n\lambda_if_i(\boldsymbol{x},y)
\end{aligned}
$$
显然这个函数只与$\boldsymbol{\lambda}$有关，令其为$\Psi(\boldsymbol{\lambda})$，于是求这个函数的最大值即可
$$
\hat{\boldsymbol{\lambda}}=\arg\max_\boldsymbol{\lambda}\Psi(\boldsymbol{\lambda})
$$
但是这个函数是很难求解析解的，因此需要运用数值方法求解
## 与最大似然的关系
## 与逻辑回归的关系
设二分类的最大熵模型仅有一个特征函数，且特征函数为
$$
f(\boldsymbol{x},y)=
\begin{cases}
\boldsymbol{w}^\top\boldsymbol{x},&y=1\\
0&y=0
\end{cases}
$$
带入最大熵模型的公式有
$$
\begin{aligned}
P(y=1|\boldsymbol{x})&=\frac{\exp\lambda\boldsymbol{w}^\top\boldsymbol{x}}{Z_\lambda(\boldsymbol{x})}\\
&=\frac{\exp\lambda\boldsymbol{w}^\top\boldsymbol{x}}{1+\exp\lambda\boldsymbol{w}^\top\boldsymbol{x}}\\
&=\frac{1}{1+\exp(-\lambda\boldsymbol{w}^\top\boldsymbol{x})}
\end{aligned}
$$
显然和逻辑回归完全等价，因此逻辑回归就是一个特征函数为线性函数的最大熵模型
## 总结
最大熵模型从理论上讲那是很有道理的，但是实际中应用并没有很多。从最后的求解模型可以看出，此模型最后的解高度依赖于特征函数，即如何将约束条件转换为特征函数，这将完全取决于你的经验
因为构造合适的特征函数很难，而且最终的求解很难求解析解，故一般不会直接使用最大熵模型
