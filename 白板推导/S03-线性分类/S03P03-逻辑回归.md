# S03P03-逻辑回归
## 逻辑回归
设二分类样本$D=\{(X_i,y_i)\}_{i=1}^N,X_i\in\mathbb{R}^p,y_i\in\{0,1\}$
$$
\begin{gathered}
X=\begin{pmatrix}X_1&X_2&\cdots&X_N\end{pmatrix}\\
Y=\begin{pmatrix}y_1&y_2&\cdots&y_N\end{pmatrix}^T
\end{gathered}
$$
引入一个sigmoid function
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
![sigmoid](https://s1.ax1x.com/2020/04/17/JERgG4.png)
那么逻辑回归模型为
$$
\begin{aligned}
\pi(X)&=P(y=1|X)=\frac{1}{1+e^{-W^TX}}\\
1-\pi(X)&=P(y=0|X)=1-p_1=\frac{e^{-W^TX}}{1+e^{-W^TX}}
\end{aligned}
$$
统一起来可写为
$$
P(y|X)=[\pi(X)]^y[1-\pi(X)]^{1-y}
$$
### loss function
用极大似然估计的方法
$$
\begin{aligned}
\hat{W}&=\arg\max_WL(W)=\arg\max_W\log P(Y|X)\\
&=\arg\max_W\log\prod_{i=1}^NP(y_i|X_i)\\
&=\arg\max_W\sum_{i=1}^N\log P(y_i|X_i)\\
&=\arg\max_W\sum_{i=1}^N[y_i\log \pi(X_i)+(1-y_i)\log (1-\pi(X_i))]\\
&=\arg\max_W\sum_{i=1}^N[y_i\log\frac{\pi(X_i)}{1-\pi(X_i)}+\log (1-\pi(X_i))]\\
&=\arg\max_W\sum_{i=1}^N[y_iW^TX_i-\log(1+\exp(W^TX_i))]
\end{aligned}
$$
从上面推导可看出，这个损失函数实际为负的交叉熵
### 求解
这个损失函数的优化问题一般采用梯度下降或者拟牛顿法进行求解，以梯度下降法为例
$$
\begin{aligned}
\nabla_{L(W)}&=\sum_{i=1}^N\left[y_iX_i-\frac{X_i\exp(W^TX_i)}{1+\exp(W^TX_i)}\right]\\
&=\sum_{i=1}^N\left[y_iX_i-\frac{1}{1+\exp(-W^TX_i)}X_i\right]\\
&=\sum_{i=1}^N[y_i-\pi(X_i)]X_i
\end{aligned}
$$
* 根据梯度下降法，每一轮迭代公式为
  $$
  W\leftarrow W+\eta\sum_{i=1}^N[y_i-\pi(X_i)]X_i\quad\eta\in(0,1]
  $$
* 根据随机梯度下降法，每一轮迭代公式为
  $$
  W\leftarrow W+\eta[y_i-\pi(X_i)]X_i\quad\eta\in(0,1]
  $$