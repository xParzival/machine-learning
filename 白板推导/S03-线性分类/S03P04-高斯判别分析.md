# S03P04-高斯判别分析
## 高斯判别分析(GDA)
设二分类样本$D=\{(X_i,y_i)\}_{i=1}^N,X_i\in\mathbb{R}^p,y_i\in\{0,1\}$
$$
\begin{gathered}
X=\begin{pmatrix}X_1&X_2&\cdots&X_N\end{pmatrix}\\
Y=\begin{pmatrix}y_1&y_2&\cdots&y_N\end{pmatrix}^T
\end{gathered}
$$
模型的目的就是通过已知的$X$预测$y$，即求$P(y|X)$。根据贝叶斯定理我们知道
$$
P(y|X)=\frac{P(X,y)}{P(X)}=\frac{P(X|y)P(y)}{P(X)}
$$
那么如果要求$P(y|X)$即要求出$P(X,y)$。所以高斯判别模型是生成模型，它可以求出联合概率分布$P(X,y)$，然后根据这个联合概率分布进一步作出预测
### 似然函数
因为$P(X,y)=P(X|y)P(y)$，所以我们对于$X|y$和$y$先给出两个基本假设：
1. 假设先验分布$y\sim Bernoulli(\Phi)$，那么
   $$
   P(y)=
   \begin{cases}
   \Phi^y,&y=1\\
   (1-\Phi)^{(1-y)},&y=0
   \end{cases}
   \Rightarrow P(y)=\Phi^y(1-\Phi)^{(1-y)}
   $$
2. 假设$y=1$和$y=0$的条件下$X$都服从高斯分布，且两个高斯分布的协方差矩阵相同即
   $$
   \begin{cases}
   X|y=1\sim N(\mu_1,\Sigma)\\
   X|y=0\sim N(\mu_0,\Sigma)
   \end{cases}
   \Rightarrow P(X|y)=N(\mu_1,\Sigma)^{(y)}N(\mu_0,\Sigma)^{(1-y)}
   $$

令$\theta=(\Phi,\mu_0,\mu_1,\Sigma)$，对数似然函数为$L(\theta)$
$$
\begin{aligned}
L(\theta)&=\log P(X,Y)\\
&=\sum_{i=1}^N\log P(X_i,y_i)\\
&=\sum_{i=1}^N\log P(X_i|y_i)P(y_i)\\
&=\sum_{i=1}^N[\log P(X_i|y_i)+\log P(y_i)]\\
&=\sum_{i=1}^N[\log N(\mu_1,\Sigma)^{(y_i)}N(\mu_0,\Sigma)^{(1-y_i)}+\log\Phi^{y_i}(1-\Phi)^{(1-y_i)}]\\
&=\sum_{i=1}^N[y_i\log N(\mu_1,\Sigma)+(1-y_i)\log N(\mu_0,\Sigma)+y_i\log\Phi+(1-y_i)\log(1-\Phi)]
\end{aligned}
$$
### 参数求解
设$y=0$的样本集为$D_0,|D_0|=N_0$，$y=1$的样本样本集为$D_1,|D_1|=N_1$
令$L(\theta)=L_0+L_1+L_2$，其中
$$
\begin{gathered}
L_0=\sum_{i=1}^N(1-y_i)\log N(\mu_0,\Sigma)\\
L_1=\sum_{i=1}^Ny_i\log N(\mu_1,\Sigma)\\
L_2=\sum_{i=1}^Ny_i\log\Phi+(1-y_i)\log(1-\Phi)
\end{gathered}
$$
根据极大似然估计有$\hat{\theta}=\arg\max\limits_\theta L(\theta)$
1. 求$\Phi$
   $$
   \begin{gathered}
   \frac{\partial L(\theta)}{\partial\Phi}=\frac{\partial L_2}{\partial\Phi}=\sum_{i=1}^N\left[y_i{1\over\Phi}+(1-y_i)(-{1\over{1-\Phi}})\right]=0\\
   \Rightarrow\Phi=\frac{\sum_{i=1}^Ny_i}{N}=\frac{N_1}{N}
   \end{gathered}
   $$
2. 求$\mu_0,\mu_1$
   $$
   \begin{aligned}
   \mu_1&=\arg\max_{\mu_1}L(\theta)=\arg\max_{\mu_1}L_1\\
   &=\arg\max_{\mu_1}\sum_{i=1}^Ny_i\log N(\mu_1,\Sigma)\\
   &=\arg\max_{\mu_1}\sum_{i=1}^Ny_i\log\left({1\over(2\pi)^{p/2}|\Sigma|^{1/2}}\exp[-{1\over 2}(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)]\right)\\
   &=\arg\min_{\mu_1}\sum_{i=1}^Ny_i(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)
   \end{aligned}
   $$
   令$\Delta=\sum_{i=1}^Ny_i(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)$
   $$
   \begin{gathered}
   \frac{\partial\Delta}{\partial\mu_1}=2\Sigma^{-1}\sum_{i=1}^Ny_i(\mu_1-X_i)=0\\
   \Rightarrow\hat{\mu_1}=\frac{\sum\limits_{i=1}^Ny_iX_i}{\sum_{i=1}^Ny_i}=\frac{\sum\limits_{X_i\in D_1}X_i}{N_1}
   \end{gathered}
   $$
   同理可得
   $$
   \hat{\mu_0}=\frac{\sum\limits_{X_i\in D_0}X_i}{N_0}
   $$
3. 求$\Sigma$
   $$
   \begin{gathered}
   \begin{aligned}
   L_1&=\sum_{i=1}^Ny_i\log N(\mu_1,\Sigma)=\sum\limits_{X_i\in D_1}\log N(\mu_1,\Sigma)\\
   &=\sum\limits_{X_i\in D_1}\log\left({1\over(2\pi)^{p/2}|\Sigma|^{1/2}}\exp[-{1\over 2}(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)]\right)\\
   &=\sum\limits_{X_i\in D_1}\left[\log{1\over(2\pi)^{p/2}}-{1\over 2}\log|\Sigma|-{1\over 2}(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)\right]\\
   &=C-{1\over 2}\sum\limits_{X_i\in D_1}\{\log|\Sigma|+tr[(X_i-\mu_1)^T\Sigma^{-1}(X_i-\mu_1)]\}\\
   &=C-{1\over 2}\sum\limits_{X_i\in D_1}\log|\Sigma|-{1\over 2}\sum\limits_{X_i\in D_1}(tr[(X_i-\mu_1)(X_i-\mu_1)^T\Sigma^{-1}])\\
   &=C-{1\over 2}N_1\log|\Sigma|-{1\over 2}tr\left[N_1\left(\sum\limits_{X_i\in D_1}{1\over{N_1}}(X_i-\mu_1)(X_i-\mu_1)^T\right)\Sigma^{-1}\right]\\
   &=C-{1\over 2}N_1\log|\Sigma|-{1\over 2}N_1tr(S_1\Sigma^{-1})
   \end{aligned}\\
   \\
   \Rightarrow\frac{\partial L_1}{\partial\Sigma}=-{N_1\over 2}(\Sigma^{-1}-S_1\Sigma^{-2})
   \end{gathered}
   $$
   同理可得
   $$
   \frac{\partial L_0}{\partial\Sigma}=-{N_0\over 2}(\Sigma^{-1}-S_0\Sigma^{-2})
   $$
   于是令
   $$
   \begin{gathered}
   \begin{aligned}
   \frac{\partial L(\theta)}{\partial\Sigma}&=\frac{\partial L_0}{\partial\Sigma}+\frac{\partial L_1}{\partial\Sigma}\\
   &=-{N_0\over 2}(\Sigma^{-1}-S_0\Sigma^{-2})-{N_1\over 2}(\Sigma^{-1}-S_1\Sigma^{-2})\\
   &=-{N\over 2}\Sigma^{-1}+\frac{N_0S_0+N_1S_1}{2}\Sigma^{-2}\\
   &=0
   \end{aligned}\\
   \Rightarrow\hat{\Sigma}=\frac{N_0S_0+N_1S_1}{N}
   \end{gathered}
   $$