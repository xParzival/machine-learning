# S06P04-隐马尔科夫模型
## 隐马尔科夫模型(Hidden Markov Model)
对于一般的概率图模型，我们认为各样本之间是独立同分布的，但是也可以认为样本之间不独立，而且是关于一个时间序列隐变量生成的，这样在概率图模型中添加了时间序列的系统称为动态模型(dynamic model)
HMM就是一种动态模型，可以认为样本是由一个隐藏的马尔科夫链生成不可观测的状态随机序列，称为状态序列；再由每个状态生成一个观测，最终生成整个样本的观测序列。可以把序列的每一个位置看作一个时刻，在HMM中的状态随机序列是离散的
### 定义
先定义一些符号
设$I=(i_1,i_2,\cdots,i_T)$是长度为$T$的状态序列，$O=(o_1,o_2,\cdots,o_T)$为对应的观测序列
设$Q=\{q_1,q_2,\cdots,q_N\}$是每个状态所有取值的集合，$V=\{v_1,v_2,\cdots,v_M\}$是每个观测所有取值的集合
根据上面述定义，可以画出如下概率有向图
<div align=center>
<img src="https://s1.ax1x.com/2020/05/12/YtEJsJ.png" />
</div>

HMM由三个参数确定
1. 初始概率分布$\pi$：对应的是初始状态的概率向量$\pi=(\pi_i)$，其中
   $$
   \pi_i=P(i_1=q_i),\quad i=1,2,\cdots,N
   $$
   即时刻$t=1$时处于状态$q_i$的概率
2. 状态转移矩阵$A$：$A=[a_{ij}]_{N\times N}$，其中
   $$
   a_{ij}=P(i_{t+1}=q_j|i_t=q_i),\quad i=1,2,\cdots,N;j=1,2,\cdots,N
   $$
   即在$t$时刻处于状态$q_i$，而在$t+1$时刻转移到状态$q_{j}$的概率
3. 观测概率矩阵$B$，又叫发射矩阵：$B=[b_j(k)]_{N\times M}$，其中
   $$
   b_j(k)=P(o_t=v_k|i_t=q_j),\quad k=1,2,\cdots,M;j=1,2,\cdots,N
   $$
   即在$t$时刻处于状态$q_j$的条件下生成$o_t=v_k$的概率

根据这三个参数，就可以确定HMM，称为HMM的三要素，统一写为
$$
\lambda=(\pi,A,B)
$$
根据以上的定义，可以发现HMM基于以下两点基本假设
1. 齐次马尔科夫性假设：假设隐藏的马尔科夫链在任意时刻$t$的状态只与前一时刻的状态相关，而与其他时刻的状态和观测无关，也与时刻$t$无关
   $$
   P(i_{t}|i_{t-1},\cdots,i_1,o_{t-1},\cdots,o_1)=P(i_t|i_{t-1}),\quad t=1,2,\cdots,T
   $$
2. 观测独立性假设：假设任意时刻的观测只依赖于该时刻的马尔科夫链的状态，而与其他观测及状态无关
   $$
   P(o_t|i_1,i_2,\cdots,i_T,o_1,\cdots,o_{t-1},o_{t+1},\cdots,o_T)=P(o_t|i_t),\quad t=1,2,\cdots,T
   $$

HMM包含了三个基本问题
1. 概率计算问题。关于参数$\lambda$和观测序列$O$，计算$P(O|\lambda)$
2. 学习问题。已知观测序列$O$，估计参数$\lambda$
3. 预测问题，又称为解码(decoding)问题。已知参数$\lambda$和观测序列$O$，求对应最有可能的状态序列，即使$P(I|O,\lambda)$最大的状态序列$I$

### 概率计算问题
$$
\begin{aligned}
P(O|\lambda)&=\sum_IP(O,I|\lambda)\\
&=\sum_IP(O|I,\lambda)P(I|\lambda)
\end{aligned}
$$
计算$P(I|\lambda)$，利用齐次马尔科夫性假设
$$
\begin{aligned}
P(I|\lambda)&=P(i_1,i_2,\cdots,i_T|\lambda)\\
&=P(i_T|i_{T-1},\cdots,i_1,\lambda)P(i_{T-1},\cdots,i_1|\lambda)\\
&=P(i_T|i_{T-1},\lambda)P(i_{T-1},\cdots,i_1|\lambda)\\
&=\cdots\\
&=P(i_T|i_{T-1},\lambda)P(i_{T-1}|i_{T-2},\lambda)\cdots P(i_2|i_1,\lambda)P(i_1,\lambda)\\
&=a_{i_{T-1}i_T}a_{i_{T-2}i_{T-1}}\cdots a_{i_2i_1}\pi_{i_1}\\
&=\pi_{i_1}\prod_{t=2}^Ta_{i_{t-1}i_t}
\end{aligned}
$$
计算$P(O|I,\lambda)$，利用观测独立性假设
$$
\begin{aligned}
P(O|I,\lambda)&=P(o_1,\cdots,o_T|i_1,i_2,\cdots,i_T,\lambda)\\
&=P(o_T|o_1,\cdots,o_{T-1},i_1,i_2,\cdots,i_T,\lambda)P(o_1,\cdots,o_{T-1}|i_1,i_2,\cdots,i_T,\lambda)\\
&=P(o_T|i_T,\lambda)P(o_1,\cdots,o_{T-1}|i_1,i_2,\cdots,i_T,\lambda)\\
&=\cdots\\
&=P(o_T|i_T,\lambda)P(o_{T-1}|i_{T-1},\lambda)\cdots P(o_1|i_1,\lambda)\\
&=b_{i_T}(o_T)b_{i_{T-1}}(o_{T-1})\cdots b_{i_1}(o_1)\\
&=\prod_{t=1}^Tb_{i_t}(o_t)
\end{aligned}
$$
代入即得
$$
\begin{aligned}
P(O|\lambda)=\sum_I\pi_{i_1}\prod_{t=2}^Ta_{i_{t-1}i_t}\prod_{t=1}^Tb_{i_t}(o_t)
\end{aligned}
$$
这样可以算出来，但是可以发现，当时刻$T$越大，状态取值$N$越多，计算复杂度为$O(TN^T)$，这种直接计算的方法计算难度是非常大的，因此有了简化计算的其他算法
#### 前向算法
<div align=center>
<img src="https://s1.ax1x.com/2020/05/13/YapQ58.png" />
</div>

定义图中虚框内的联合概率，即$t$时刻之前的观测序列为$o_1,o_2,\cdots,o_t$及$t$时刻的状态为$q_i$的概率
$$
\begin{aligned}
\alpha_t(i)&=P(o_1,o_2,\cdots,o_t,i_t=q_i|\lambda)\\
&=\sum_{j=1}^NP(o_1,o_2,\cdots,o_t,i_t=q_i,i_{t-1}=q_j|\lambda)\\
&=\sum_{j=1}^NP(o_t|o_1,o_2,\cdots,o_{t-1},i_t=q_i,i_{t-1}=q_j,\lambda)P(o_1,o_2,\cdots,o_{t-1},i_t=q_i,i_{t-1}=q_j|\lambda)\\
&=\sum_{j=1}^NP(o_t|i_t=q_i,\lambda)P(i_t=q_i|o_1,o_2,\cdots,o_{t-1},i_{t-1}=q_j,\lambda)P(o_1,o_2,\cdots,o_{t-1},i_{t-1}=q_j|\lambda)\\
&=\sum_{j=1}^NP(o_t|i_t=q_i,\lambda)P(i_t=q_i|i_{t-1}=q_j,\lambda)\alpha_{t-1}(j)\\
&=P(o_t|i_t=q_i,\lambda)\sum_{j=1}^NP(i_t=q_i|i_{t-1}=q_j,\lambda)\alpha_{t-1}(j)\\
&=b_i(o_t)\sum_{j=1}^N\alpha_{t-1}(j)a_{ji}
\end{aligned}
$$
由此式可看出$\alpha_t(i)$关于时刻$t$的递归关系，又因为
$$
P(O|\lambda)=\sum_{i=1}^NP(o_1,o_2,\cdots,o_T,i_T=q_i|\lambda)=\sum_{i=1}^N\alpha_T(i)
$$
于是通过递归可以计算出$P(O|\lambda)$，这里$\alpha_t(i)$又称为前向概率，这种计算$P(O|\lambda)$的方法称为观测序列概率的前向算法。下面总结前向算法流程
> (1)计算初值
> $$
> \begin{aligned} 
> \alpha_1(i)&=P(o_1,i_1=q_i|\lambda)\\
> &=P(o_1|i_1=q_i,\lambda)P(i_1=q_i|\lambda)\\
> &=\pi_ib_i(o_1)\quad i=1,2,\cdots,N
> \end{aligned}
> $$
> (2)对$t=1,2,\cdots,T-1$递推计算
> $$
> \alpha_{t+1}(i)=b_i(o_{t+1})\sum_{j=1}^N\alpha_t(j)a_{ji}\quad i=1,2,\cdots,N
> $$
> (3)计算终值
> $$
> P(O|\lambda)=\sum_{i=1}^N\alpha_T(i)
> $$

显然这个算法的计算法复杂度为$O(N^2T)$，比直接计算更简便更高效
#### 后向算法
<div align=center>
<img src="https://s1.ax1x.com/2020/05/13/Yamozq.png" />
</div>

定义图中虚框内的条件概率，即$t$时刻之后的观测序列为$o_{t+1},o_{t+2},\cdots,o_T$在$t$时刻的状态为$q_i$条件下的概率
$$
\begin{aligned}
\beta_t(i)&=P(o_{t+1},o_{t+2},\cdots,o_T|i_t=q_i,\lambda)\\
&=\sum_{j=1}^NP(o_{t+1},o_{t+2},\cdots,o_T,i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\sum_{j=1}^NP(o_{t+1},o_{t+2},\cdots,o_T|i_{t+1}=q_j,i_t=q_i,\lambda)P(i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\sum_{j=1}^Na_{ij}P(o_{t+1},o_{t+2},\cdots,o_T|i_{t+1}=q_j,\lambda)\\
&=\sum_{j=1}^Na_{ij}P(o_{t+1}|o_{t+2},\cdots,o_T,i_{t+1}=q_j,\lambda)P(o_{t+2},\cdots,o_T|i_{t+1}=q_j,\lambda)\\
&=\sum_{j=1}^Na_{ij}P(o_{t+1}|i_{t+1}=q_j,\lambda)\beta_{t+1}(j)\\
&=\sum_{j=1}^Na_{ij}b_j(o_{t+1})\beta_{t+1}(j)
\end{aligned}
$$
由此式可看出$\beta_t(i)$关于时刻$t$的递归关系，又因为
$$
\begin{aligned}
P(O|\lambda)&=\sum_{i=1}^NP(o_1,o_2,\cdots,o_T,i_1=q_i|\lambda)\\
&=\sum_{i=1}^NP(o_1,o_2,\cdots,o_T|i_1=q_i,\lambda)P(i_1=q_i|\lambda)\\
&=\sum_{i=1}^N\pi_iP(o_1|o_2,\cdots,o_T,i_1=q_i,\lambda)P(o_2,\cdots,o_T|i_1=q_i,\lambda)\\
&=\sum_{i=1}^N\pi_iP(o_1|i_1=q_i,\lambda)\beta_1(i)\\
&=\sum_{i=1}^N\pi_ib_i(o_1)\beta_1(i)
\end{aligned}
$$
于是通过递归可以计算出$P(O|\lambda)$，这里$\beta_t(i)$又称为后向概率，这种计算$P(O|\lambda)$的方法称为观测序列概率的后向算法。下面总结后向算法流程
> (1)规定初值
> 根据定义，$\beta_T(i)$应该为$T$时刻之后的观测序列为$o_{T+1},o_{T+2},\cdots$在$T$时刻的状态为$q_i$条件下的概率，而实际上$T$时刻之后的观测序列是未知的，那么取$Q$中任何值都可能，因此将其概率规定为1
> $$
> \beta_T(i)=1
> $$
> (2)对$t=T-1,T-2,\cdots,1$递推计算
> $$
> \beta_{t}(i)=\sum_{j=1}^Na_{ij}b_j(o_{t+1})\beta_{t+1}(j)\quad i=1,2,\cdots,N
> $$
> (3)计算终值
> $$
> P(O|\lambda)=\sum_{i=1}^N\pi_ib_i(o_1)\beta_1(i)
> $$

#### 相关概率值的计算
$$
\begin{aligned}
\alpha_t(i)\beta_t(i)&=P(o_1,o_2,\cdots,o_t,i_t=q_i|\lambda)P(o_{t+1},o_{t+2},\cdots,o_T|i_t=q_i,\lambda)\\
&=P(o_1,o_2,\cdots,o_t|i_t=q_i,\lambda)P(i_t=q_i|\lambda)P(o_{t+1},o_{t+2},\cdots,o_T|i_t=q_i,\lambda)\\
&=P(o_1,o_2,\cdots,o_t,o_{t+1},o_{t+2},\cdots,o_T|i_t=q_i,\lambda)P(i_t=q_i|\lambda)\\
&=P(o_1,o_2,\cdots,o_T,i_t=q_i|\lambda)\\
&=P(O,i_t=q_i|\lambda)
\end{aligned}
$$
即给定模型$\lambda$条件下，时刻$t$状态为$q_i$且观测序列为$O$的概率为
$$
P(O,i_t=q_i|\lambda)=\alpha_t(i)\beta_t(i)
$$
因此可得
$$
P(O|\lambda)=\sum_{i=1}^NP(O,i_t=q_i|\lambda)=\sum_{i=1}^N\alpha_t(i)\beta_t(i)
$$
下面计算模型参数为$\lambda$下，观测序列为$O$且$i_t=q_i,i_{t+1}=q_j$的概率
$$
\begin{aligned}
P(O,i_t=q_i,i_{t+1}=q_j|\lambda)&=P(o_1,o_2,\cdots,o_T,i_t=q_i,i_{t+1}=q_j|\lambda)\\
&=P(o_{t+1},\cdots,o_T,i_{t+1}=q_j|o_1,o_2,\cdots,o_t,i_t=q_i,\lambda)P(o_1,o_2,\cdots,o_t,i_t=q_i|\lambda)\\
&=\alpha_t(i)P(o_{t+1},\cdots,o_T,i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\alpha_t(i)P(o_{t+2},\cdots,o_T|o_{t+1},i_{t+1}=q_j,i_t=q_i,\lambda)P(o_{t+1},i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\alpha_t(i)P(o_{t+2},\cdots,o_T|i_{t+1}=q_j,\lambda)P(o_{t+1},i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\alpha_t(i)\beta_{t+1}(j)P(o_{t+1}|i_t=q_i,i_{t+1}=q_j,\lambda)P(i_{t+1}=q_j|i_t=q_i,\lambda)\\
&=\alpha_t(i)a_{ij}\beta_{t+1}(j)P(o_{t+1}|i_{t+1}=q_j,\lambda)\\
&=\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)
\end{aligned}
$$
### 学习问题
学习问题其实就是参数$\lambda$的估计，由概率计算问题已经计算出了$P(O|\lambda)$，于是运用极大似然估计来计算参数。因为HMM中含有隐变量，因此采用EM算法来求解这个极大似然估计问题
$$
\begin{aligned}
\lambda^{(s+1)}&=\arg\max_\lambda\sum_IP(I|O,\lambda^{(s)})\log P(O,I|\lambda) \\
&=\arg\max_\lambda\sum_I\frac{P(O,I|\lambda^{(s)})}{P(O|\lambda^{(s)})}\log P(O,I|\lambda)\\
&=\arg\max_\lambda\frac{1}{P(O|\lambda^{(s)})}\sum_IP(O,I|\lambda^{(s)})\log P(O,I|\lambda)\\
&=\arg\max_\lambda\sum_IP(O,I|\lambda^{(s)})\log P(O,I|\lambda)\\
\end{aligned}
$$
令$Q(\lambda,\lambda^{(s)})=\sum_IP(O,I|\lambda^{(s)})\log P(O,I|\lambda)$，将直接计算法得到的$P(O,I|\lambda)$代入
$$
\begin{aligned}
Q(\lambda,\lambda^{(s)})&=\sum_IP(O,I|\lambda^{(s)})\log\pi_{i_1}\prod_{t=2}^Ta_{i_{t-1}i_t}\prod_{t=1}^Tb_{i_t}(o_t)\\
&=\sum_IP(O,I|\lambda^{(s)})\left[\log\pi_{i_1}+\sum_{t=1}^{T-1}\log a_{i_ti_{t+1}}+\sum_{t=1}^T\log b_{i_t}(o_t)\right]\\
\end{aligned}
$$
1. 求$\pi^{(s+1)}$
   $$
   \begin{aligned}
   \pi^{(s+1)}&=\arg\max_\pi Q(\lambda,\lambda^{(s)})\\
   &=\arg\max_\pi\sum_IP(O,I|\lambda^{(s)})\log\pi_{i_1}\\
   &=\arg\max_\pi\sum_{i_1}\cdots\sum_{i_T}P(i_1,i_2,\cdots,i_T,O|\lambda^{(s)})\log\pi_{i_1}\\
   &=\arg\max_\pi\sum_{i_1}\log\pi_{i_1}\sum_{i_2}\cdots\sum_{i_T}P(i_1,i_2,\cdots,i_T,O|\lambda^{(s)})\\
   &=\arg\max_\pi\sum_{i_1}\log\pi_{i_1}P(i_1,O|\lambda^{(s)})\\
   &=\arg\max_\pi\sum_{i=1}^N\log\pi_{i}P(i_1=q_i,O|\lambda^{(s)})
   \end{aligned}
   $$
   于是转化为如下优化问题
   $$
   \begin{gathered}
   \max_\pi\sum_{i=1}^N\log\pi_{i}P(i_1=q_i,O|\lambda^{(s)})\\
   s.t.\quad\sum_{i=1}^N\pi_i=1
   \end{gathered}
   $$
   显然利用拉格朗日乘子法
   $$
   \begin{gathered}
   L(\pi,\eta)=\sum_{i=1}^N\log\pi_{i}P(i_1=q_i,O|\lambda^{(s)})+\eta(1-\sum_{i=1}^N\pi_i)\\
   \begin{aligned}
   &\Rightarrow\frac{\partial L}{\partial\pi_i}=\frac{P(i_1=q_i,O|\lambda^{(s)})}{\pi_{i}}-\eta=0\\
   &\Rightarrow\eta\pi_{i}=P(i_1=q_i,O|\lambda^{(s)})\\
   &\Rightarrow\sum_{i=1}^N\eta\pi_{i}=\sum_{i=1}^NP(i_1=q_i,O|\lambda^{(s)})\\
   &\Rightarrow\eta=P(O|\lambda^{(s)})\\
   &\Rightarrow\pi_{i}^{(s+1)}=\frac{P(i_1=q_i,O|\lambda^{(s)})}{P(O|\lambda^{(s)})}
   \end{aligned}\\
   \\
   \pi^{(s+1)}=(\pi_1^{(s+1)},\pi_2^{(s+1)},\cdots,\pi_N^{(s+1)})
   \end{gathered}
   $$
2. 求$A^{(s+1)}$
   $$
   \begin{aligned}
   A^{(s+1)}&=\arg\max_AQ(\lambda,\lambda^{(s)})\\
   &=\arg\max_A\sum_IP(O,I|\lambda^{(s)})\sum_{t=1}^{T-1}\log a_{i_ti_{t+1}}\\
   &=\arg\max_A\sum_IP(O,I|\lambda^{(s)})\sum_{t=1}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_IP(O,I|\lambda^{(s)})\log P(i_2|i_1)+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_{i_1}\cdots\sum_{i_T}P(O,i_1,i_2,\cdots,i_T|\lambda^{(s)})\log P(i_2|i_1)+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_{i_1}\sum_{i_2}\log P(i_2|i_1)\sum_{i_3}\cdots\sum_{i_T}P(O,i_1,i_2,\cdots,i_T|\lambda^{(s)})+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_{i_1}\sum_{i_2}\log P(i_2|i_1)P(O,i_1,i_2|\lambda^{(s)})+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_1=q_i,i_2=q_j|\lambda^{(s)})+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^{T-1}\log P(i_{t+1}=q_j|i_t=q_i)\\
   &=\arg\max_A\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_1=q_i,i_2=q_j|\lambda^{(s)})+\cdots+\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_{T-1}=q_i,i_T=q_j|\lambda^{(s)})\\
   &=\arg\max_A\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})
   \end{aligned}
   $$
   由定义知矩阵$A$是一个概率分布的矩阵，其每一行的和为1，因此最终转化为如下优化问题
   $$
   \begin{gathered}
   \max_A\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})\\
   s.t.\quad\sum_{j=1}^Na_{ij}=1,\quad i=1,2,\cdots,N
   \end{gathered}
   $$
   利用拉格朗日乘子法
   $$
   L(A,\eta)=\sum_{t=1}^{T-1}\sum_{i=1}^N\sum_{j=1}^N\log a_{ij}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})+\sum_{i=1}^N\eta_i(1-\sum_{j=1}^Na_{ij})
   $$
   对矩阵$A$的每一个元素求偏导
   $$
   \begin{gathered}
   \frac{\partial L}{\partial a_{ij}}=\frac{1}{a_{ij}}\sum_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})-\eta_i=0\\
   \begin{aligned}
   \Rightarrow& a_{ij}=\frac{1}{\eta_i}\sum_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})\\
   \Rightarrow&\sum_{j=1}^Na_{ij}=\sum_{j=1}^N\frac{1}{\eta_i}\sum_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})\\
   &\begin{aligned}
   \Rightarrow\eta_i&=\sum_{j=1}^N\sum_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})\\
   &=\sum_{t=1}^{T-1}\sum_{j=1}^NP(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})\\
   &=\sum_{t=1}^{T-1}P(O,i_t=q_i|\lambda^{(s)})
   \end{aligned}
   \end{aligned}
   \end{gathered}
   $$
   代入即得
   $$
   \begin{gathered}
   a_{ij}^{(s+1)}=\frac{\sum\limits_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})}{\sum\limits_{t=1}^{T-1}P(O,i_t=q_i|\lambda^{(s)})}
   \end{gathered}
   $$
3. 求$B^{(s+1)}$
   $$
   \begin{aligned}
   B^{(s+1)}&=\arg\max_BQ(\lambda,\lambda^{(s)})\\
   &=\arg\max_B\sum_IP(O,I|\lambda^{(s)})\sum_{t=1}^T\log b_{i_t}(o_t)\\
   &=\arg\max_B\sum_IP(O,I|\lambda^{(s)})\log b_{i_1}(o_1)+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^T\log b_{i_t}(o_t)\\
   &=\arg\max_B\sum_{i_1}\cdots\sum_{i_T}P(O,i_1,\cdots,i_T|\lambda^{(s)})\log P(o_1=v_k|i_1=q_j)+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^T\log b_{i_t}(o_t)\\
   &=\arg\max_B\sum_{i_1}\log P(o_1=v_k|i_1=q_j)\sum_{i_2}\cdots\sum_{i_T}P(O,i_1,\cdots,i_T|\lambda^{(s)})+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^T\log b_{i_t}(o_t)\\
   &=\arg\max_B\sum_{i_1}P(O,i_1|\lambda^{(s)})\log P(o_1=v_k|i_1=q_j)+\sum_IP(O,I|\lambda^{(s)})\sum_{t=2}^T\log b_{i_t}(o_t)\\
   &=\arg\max_B\sum_{i_1}P(O,i_1|\lambda^{(s)})\log P(o_1=v_k|i_1=q_j)+\cdots+\sum_{i_T}P(O,i_T|\lambda^{(s)})\log P(o_T=v_k|i_T=q_j)\\
   &=\arg\max_B\sum_{t=1}^T\sum_{i_t}P(O,i_t|\lambda^{(s)})\log P(o_t=v_k|i_t=q_j)\\
   &=\arg\max_B\sum_{t=1}^T\sum_{j=1}^NP(O,i_t=q_j|\lambda^{(s)})\log b_j(o_t)
   \end{aligned}
   $$
   根据定义矩阵$B$是概率矩阵，满足每行的和为1，于是转化为如下优化问题
   $$
   \begin{gathered}
   \max_B\sum_{t=1}^T\sum_{j=1}^NP(O,i_t=q_j|\lambda^{(s)})\log b_j(o_t)\\
   s.t. \sum_{k=1}^Mb_j(k)=1,\quad j=1,2,\cdots,N
   \end{gathered}
   $$
   根据拉格朗日乘子法
   $$
   L(B,\eta)=\sum_{t=1}^T\sum_{j=1}^NP(O,i_t=q_j|\lambda^{(s)})\log b_j(o_t)+\sum_{j=1}^N\eta_j(1-\sum_{k=1}^Mb_j(k))
   $$
   对矩阵$B$的每一个元素求偏导。这里需要注意的是，只有$o_t=v_k$的$b_i(o_t)$求导不为零，其余的项求导均为零
   $$
   \begin{gathered}
   \frac{\partial L}{\partial b_j(k)}=\sum_{t=1}^T\frac{1}{b_j(k)}P(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)-\eta_j=0\\
   \begin{aligned}
   &\Rightarrow b_j(k)=\frac{1}{\eta_j}\sum_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)\\
   &\Rightarrow\sum_{k=1}^Mb_j(k)=\sum_{k=1}^M\frac{1}{\eta_j}\sum_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)\\
   &\begin{aligned}
   \Rightarrow\eta_j&=\sum_{t=1}^T\sum_{k=1}^MP(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)\\
   &=\sum_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})\sum_{k=1}^MI(o_t=v_k)
   \end{aligned}
   \end{aligned}
   \end{gathered}
   $$
   因为在$t$确定的时候，观测变量$o_t$等于哪个$v_k$是确定的，于是对于每一个$t$都显然有$\sum\limits_{k=1}^MI(o_t=v_k)=1$，于是可以化简为
   $$
   \eta_j=\sum_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})
   $$
   代入即可得
   $$
   b_j^{(s+1)}(k)=\frac{\sum\limits_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)}{\sum\limits_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})}
   $$

#### Baum-Welch算法
> (1)初始化参数$\lambda^{(0)}=(\pi^{(0)},A^{(0)},B^{(0)})$
> (2)对$s=1,2,\cdots$进行迭代计算
> $$
> \begin{gathered}
> \pi_{i}^{(s+1)}=\frac{P(i_1=q_i,O|\lambda^{(s)})}{P(O|\lambda^{(s)})}\\
> \\
> a_{ij}^{(s+1)}=\frac{\sum\limits_{t=1}^{T-1}P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})}{\sum\limits_{t=1}^{T-1}P(O,i_t=q_i|\lambda^{(s)})}\\
> \\
> b_j^{(s+1)}(k)=\frac{\sum\limits_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})I(o_t=v_k)}{\sum\limits_{t=1}^TP(O,i_t=q_j|\lambda^{(s)})}
> \end{gathered}
> $$
> 其中$P(O|\lambda^{(s)}),P(O,i_t=q_j|\lambda^{(s)}),P(O,i_{t}=q_i,i_{t+1}=q_j|\lambda^{(s)})$可由前后向算法计算得出
> (3)重复步骤(2)直到模型参数收敛，迭代终止得到模型参数$\lambda^{(s+1)}=(\pi^{(s+1)},A^{(s+1)},B^{(s+1)})$

### 预测问题
预测问题的本质是求对应最有可能的状态序列，即使$P(I|O,\lambda)$最大的状态序列$I=i_1,i_2,\cdots,i_T$。而对于每一个时刻$t$有$i_t=q_i\in Q$，那么可以画出如下图
<div align=center>
<img src="https://s1.ax1x.com/2020/05/17/Y2RfAK.png" />
</div>

图中每一个状态都有N种取值，箭头即可表示状态转移的路径，那么问题就转化为在这些路径中找到最有可能的一条路径。这显然是一个动态规划问题。最直接的想法当然是把所有路径的概率都计算出来，然后比较大小取概率最大的那一条路径，但是这样计算复杂度极高，为$O(N^T)$。下面介绍动态规划里面的一种方法，维特比算法
#### 维特比算法
一般地，对于类似HMM的网络，每个状态取值不一定是相同的。假设有T个状态$x_1,x_2,\cdots,x_T$，每个状态对应的取值个数为$n_1,n_2,\cdots,n_T$，可画出如下图，这种网络称为篱笆网络
<div align=center>
<img src="https://s1.ax1x.com/2020/05/17/Y252F0.png" />
</div>

对于选择路径，有如下两个事实
1. 显而易见，如果最短路径经过某个点，比如图中$i_t$状态的$q_i$点，那么这条路径上从起点到该点的子路径一定是起点到该点的最短路径
2. 如果记录了从起点到某个时刻所有节点的最短路径，那么最终最短路径一定经过其中一条

综合以上两个基本事实，在我们从时刻$t$转移到时刻$t+1$时，从起点到时刻$t$的所有节点的最短路径是已经找到并记录的，那么在计算从起点到时刻$t+1$某个节点的最短路径时，只要考虑从起点到时刻$t$的所有节点的最短路径，以及这个从时刻$t$的所有节点到时刻$t+1$某个节点的最短路径即可，这就是维特比算法的基本思想
维特比算法就是用来解决篱笆网络最优路径问题的。下面描述一下维特比算法的步骤
1. 从起点S出发到第一个状态$x_1$，其每个节点的概率就是$S$到$x_1$每个节点的最短路径，将$S$到$x_1$每个节点的最短路径记为$d(S,x_{1i})=P(x_1=q_i),i=1,2,\cdots,n_1$。根据第二个事实这些路径都要记录下来
2. 对于第二个状态，要计算$S$到$x_2$每个节点的最短路径。因为$d(S,x_{1i})$已经都记录下来了，于是要针对$x_2$每个节点计算并找到对应每个节点的最小路径并记录
   $$
   d(S,x_{2j})=\min_i[d(S,x_{1i})+d(x_{1i},x_{2j})],\quad j=1,2,\cdots,n_2
   $$
3. 对于第$t$个状态，要计算$S$到$x_t$每个节点的最短路。因为$d(S,x_{(t-1)i})$已经都记录下来了，于是要针对$x_2$每个节点计算并找到对应每个节点的最小路径并记录
   $$
   d(S,x_{tj})=\min_i[d(S,x_{(t-1)i})+d(x_{(t-1)i},x_{tj})],\quad j=1,2,\cdots,n_2
   $$
4. 以此类推计算下去最终即可求得到状态$x_T$的最短路径

设$n_1,n_2,\cdots,n_T$中最大的数为$N$，那么计算复杂度为$O(N^2T)$，显然比遍历的方法大大降低了复杂度
对于HMM的预测问题，采用维特比算法，这时的距离度量其实是概率，要找的路径是使$P(I|O,\lambda)$概率最大的路径，又因为
$$
P(I|O,\lambda)=\frac{P(I,O|\lambda)}{P(O|\lambda)}
$$
显然当给定样本时观测序列$O$是确定的，所以求$P(I|O,\lambda)$最大就是求$P(I,O|\lambda)$最大
定义从起点到时刻$t$状态为$q_i$即$i_t=q_i$的节点时所有路径中的概率最大值为，对应的路径记录下来
$$
\delta_t(i)=\max_{i_1,i_2,\cdots,i_{t-1}}P(i_t=q_i,i_{t-1},\cdots,i_1,o_t,\cdots,o_1|\lambda),\quad i=1,2,\cdots,N
$$
在时刻$t+1$状态为$q_i$即$i_{t+1}=q_i$时所有路径中的概率最大值为，时刻$t$时$\delta_t(j)$转化为状态$i_{t+1}=q_i$乘以生成$o_{t+1}$的概率最大值，即
$$
\begin{aligned}
\delta_{t+1}(i)&=\max_{i_1,i_2,\cdots,i_t}P(i_{t+1}=q_i,i_t,\cdots,i_1,o_{t+1},\cdots,o_1|\lambda)\\
&=\max_{1\le j\le N}\delta_t(j)a_{ji}b_i(o_{t+1}),\quad i=1,2,\cdots,N
\end{aligned}
$$
对应的$i_{t+1}=q_i$的节点所有路径中的概率最大路径前一时刻的节点定义为
$$
\Psi_{t+1}(i)=\arg\max_{1\le j\le N}\delta_t(j)a_{ji},\quad i=1,2,\cdots,N
$$
因为每个时刻的$\delta_t(j)$都被记录，所以就可以递推得到最终的最大概率路径
HMM中维特比算法的流程
> (1)初始化
> $$
> \begin{gathered}
> \delta_1(i)=\pi_ib_i(o_1),\quad i=1,2,\cdots,N\\
> \Psi_1(i)=0,\quad i=1,2,\cdots,N
> \end{gathered}
> $$
> (2)对$t=1,2,\cdots,T$递推计算
> $$
> \begin{gathered}
> \delta_t(i)=\max_{1\le j\le N}\delta_{t-1}(j)a_{ji}b_i(o_t),\quad i=1,2,\cdots,N\\
> \Psi_t(i)=\arg\max_{1\le j\le N}\delta_{t-1}(j)a_{ji},\quad i=1,2,\cdots,N
> \end{gathered}
> $$
> (3)得到终值
> $$
> \begin{gathered}
> P^*=\max_{1\le i\le N}\delta_T(i)\\
> i_T^*=\arg\max_{1\le i\le N}\delta_T(i)
> \end{gathered}
> $$
> (4)最优路径回溯。对$t=T-1,T-2,\cdots,1$
> $$
> i_t^*=\Psi_{t+1}(i_{t+1}^*)
> $$
> 求得最优路径即最有可能的状态序列$I=i_1^*,i_2^*,\cdots,i_T^*$