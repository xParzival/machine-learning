# S06P03-高斯混合模型
## 高斯混合模型(Gaussian Mixture Model)
高斯混合模型是指如下形式的概率分布
$$
P(X|\theta)=\sum_{k=1}^Kp_kN(X|\theta_k)
$$
其中$p_k\ge0$为权重且$\sum_{k=1}^Kp_k=1$；$N(X|\theta_k)$为高斯分布，$\theta_k=(\mu_k,\Sigma_k)$，称为第$k$个分模型
高斯混合模型其实就是多个高斯分布叠加组成的概率分布，包含了权重以及各个分模型的参数；一般混合模型可用任意模型替换高斯分布
### 案例
考虑一个学生身高的样本，假设身高是符合高斯分布的，于是可以直接用极大似然估计来求解。但是现在给出一个条件，男生和女生是符合不同的高斯分布的，此时如果知道每一个样本是什么性别，那么对男女同学分别进行极大似然估计即可；但是样本并没有给出性别，只有身高数据，于是这个问题中含有一个隐变量，即学生的性别。这就构成一个含有隐变量的高斯混合模型，可以考虑运用EM算法来求解
### EM算法参数估计
给定样本量为N的观测$X=(X_1,X_2,\cdots,X_N)$，假设其符合高斯混合模型，那么有隐变量$Z=(Z_1,Z_2,\cdots,Z_N)$，其中$Z_i=k$表示样本属于第$k$个分模型，显然可以看做$Z_i$符合如下分布
$$
\begin{array}{c|cccc}
Z_i&1&2&\cdots&K\\\hline
p&p_1&p_2&\cdots&p_k
\end{array}
$$
高斯混合模型是一个生成模型，参数$\theta=(p_1,p_2,\cdots,p_k,\mu_1,\mu_2,\cdots,\mu_k,\Sigma_1,\Sigma_2,\cdots,\Sigma_k)$。在概率图中一般用阴影表示已观测，可以画出其概率有向图
<div align=center>
<img src="https://s1.ax1x.com/2020/05/10/Y3CsfI.png" />
</div>

$$
P(X_i|\theta)=\sum_ZP(X_i,Z_i|\theta)=\sum_{k=1}^KP(X_i,Z_i=k|\theta)
$$
根据概率图，可以写出联合概率分布
$$
\begin{aligned}
P(X_i,Z_i=k|\theta)=P(Z_i=k|\theta)P(X_i|Z_i=k,\theta)=p_kN(X_i|\mu_k,\Sigma_k)
\end{aligned}
$$
因此可得后验概率
$$
P(Z_i=k|X_i,\theta)=\frac{P(Z_i=k,X_i|\theta)}{P(X_i|\theta)}=\frac{p_kN(X_i|\mu_k,\Sigma_k)}{\sum_{k=1}^Kp_kN(X_i|\mu_k,\Sigma_k)}
$$
对数似然为
$$
\begin{aligned}
L(\theta)&=\log P(X|\theta)=\sum_{i=1}^N\log P(X_i|\theta)\\
&=\sum_{i=1}^N\log\sum_{k=1}^Kp_kN(X_i|\mu_k,\Sigma_k)
\end{aligned}
$$
对于EM算法的第$t$次迭代：
1. E-Step
   计算出后验概率
   $$
   P(Z_i=k|X_i,\theta^{(t)})=\frac{p_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k^{(t)})}{\sum_{k=1}^Kp_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k)^{(t)}}
   $$
   写出$Q(\theta,\theta^{(t)})$
   $$
   \begin{aligned}
   Q(\theta,\theta^{(t)})&=E_{Z|X,\theta^{(t)}}[\log P(X,Z|\theta)]\\
   &=\sum_Z\left[P(Z|X,\theta^{(t)})\log P(X,Z|\theta)\right]\\
   &=\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\log\prod_{i=1}^NP(X_i,Z_i|\theta)\right]\\
   &=\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=1}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\log P(X_1,Z_1|\theta)+\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=2}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\log P(X_1,Z_1|\theta)\right]+\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=2}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_Z\left[\left(\prod_{i=2}^NP(Z_i|X_i,\theta^{(t)})\right)P(Z_1|X_1,\theta^{(t)})\log P(X_1,Z_1|\theta)\right]+\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=2}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_{Z_1}\left[P(Z_1|X_1,\theta^{(t)})\log P(X_1,Z_1|\theta)\right]\sum_{Z_2,\cdots,Z_N}\left(\prod_{i=2}^NP(Z_i|X_i,\theta^{(t)})\right)+\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=2}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_{Z_1}\left[P(Z_1|X_1,\theta^{(t)})\log P(X_1,Z_1|\theta)\right]+\sum_Z\left[\prod_{i=1}^NP(Z_i|X_i,\theta^{(t)})\sum_{i=2}^N\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_{Z_1}\left[P(Z_1|X_1,\theta^{(t)})\log P(X_1,Z_1|\theta)\right]+\sum_{Z_2}\left[P(Z_2|X_2,\theta^{(t)})\log P(X_2,Z_2|\theta)\right]+\cdots+\sum_{Z_N}\left[P(Z_N|X_N,\theta^{(t)})\log P(X_N,Z_N|\theta)\right]\\
   &=\sum_{i=1}^N\sum_{Z_i}\left[P(Z_i|X_i,\theta^{(t)})\log P(X_i,Z_i|\theta)\right]\\
   &=\sum_{i=1}^N\sum_{k=1}^K\left[P(Z_i=k|X_i,\theta^{(t)})\log P(X_i,Z_i=k|\theta)\right]\\
   &=\sum_{i=1}^N\sum_{k=1}^KP(Z_i=k|X_i,\theta^{(t)})\log p_kN(X_i|\mu_k,\Sigma_k)
   \end{aligned}
   $$
2. M-Step
   优化问题为
   $$
   \begin{gathered}
   \begin{aligned}
   \theta^{(t+1)}&=\arg\max_\theta Q(\theta,\theta^{(t)})\\
   &=\arg\max_\theta\sum_{i=1}^N\sum_{k=1}^KP(Z_i=k|X_i,\theta^{(t)})\log p_kN(X_i|\mu_k,\Sigma_k)
   \end{aligned}\\
   s.t.\quad\sum_{k=1}^Kp_k=1
   \end{gathered}
   $$
   定义拉格朗日乘子函数
   $$
   \begin{aligned}
   L(\theta)&=\sum_{i=1}^N\sum_{k=1}^KP(Z_i=k|X_i,\theta^{(t)})\log p_kN(X_i|\mu_k,\Sigma_k)+\lambda\left(1-\sum_{k=1}^Kp_k\right)\\
   &=\sum_{k=1}^K\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})[\log p_k+\log N(X_i|\mu_k,\Sigma_k)]+\lambda\left(1-\sum_{k=1}^Kp_k\right)
   \end{aligned}
   $$
   求$p_k^{(t+1)}$
   $$
   \begin{gathered}
   \frac{\partial L}{\partial p_k}=\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}{p_k}-\lambda=0\\
   \Rightarrow p_k=\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}{\lambda}
   \end{gathered}
   $$
   代入$\quad\sum_{k=1}^Kp_k=1$得
   $$
   \begin{gathered}
   \sum_{k=1}^K\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}{\lambda}=1\\
   \\
   \begin{aligned}
   \Rightarrow\lambda&=\sum_{k=1}^K\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\\
   &=\sum_{i=1}^N\sum_{k=1}^KP(Z_i=k|X_i,\theta^{(t)})\\
   &=\sum_{i=1}^N1\\
   &=N
   \end{aligned}\\
   \\
   \begin{aligned}
   \Rightarrow p_k^{(t+1)}&=\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}{N}\\
   &={1\over N}\sum_{i=1}^N\frac{p_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k^{(t)})}{\sum_{k=1}^Kp_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k)^{(t)}}
   \end{aligned}
   \end{gathered}
   $$
   求$\mu_k^{(t+1)},\Sigma_k^{(t+1)}$，只用把$L(\theta)$中跟$\mu_k,\Sigma_k$相关的项提出来计算就可以了
   $$
   \begin{aligned}
   L(\mu)&=\sum_{k=1}^K\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\log N(X_i|\mu_k,\Sigma_k)\\
   &=\sum_{k=1}^K\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\log\left[{1\over{(2\pi})^{p/2}|\Sigma_k|^{1/2}}\exp\left(-{1\over2}(X_i-\mu_k)^T\Sigma_k^{-1}(X_i-\mu_k)\right)\right]\\
   &=\sum_{k=1}^K\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\left[\log{1\over{(2\pi})^{p/2}|\Sigma_k|^{1/2}}-{1\over2}(X_i-\mu_k)^T\Sigma_k^{-1}(X_i-\mu_k)\right]
   \end{aligned}
   $$
   对$\mu_k$求导有
   $$
   \begin{aligned}
   \frac{\partial L}{\partial\mu_k}=\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\Sigma_k^{-1}(X_i-\mu_k)=0
   \end{aligned}\tag{1}
   $$
   对$\Sigma_k$求导有
   $$
   \begin{gathered}
   \frac{\partial L}{\partial \Sigma_k}=\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})\left[\frac{\partial}{\partial\Sigma_k}\log{1\over{(2\pi})^{p/2}|\Sigma_k|^{1/2}}-{1\over2}\frac{\partial}{\partial\Sigma_k}(X_i-\mu_k)^T\Sigma_k^{-1}(X_i-\mu_k)\right]\\
   \\
   \begin{aligned}
   \frac{\partial}{\partial\Sigma_k}\log{1\over{(2\pi})^{p/2}|\Sigma_k|^{1/2}}&=\frac{\partial}{\partial\Sigma_k}\left[-\log(2\pi)^{p/2}-{1\over2}\log|\Sigma_k|\right]\\
   &=-{1\over2}{1\over|\Sigma_k|}|\Sigma_k|\Sigma_k^{-1}\\
   &=-{\Sigma_k^{-1}\over2}
   \end{aligned}\\
   \\
   \begin{aligned}
   \frac{\partial}{\partial\Sigma_k}(X_i-\mu_k)^T\Sigma_k^{-1}(X_i-\mu_k)&=\frac{\partial}{\partial\Sigma_k}tr\left[(X_i-\mu_k)^T\Sigma_k^{-1}(X_i-\mu_k)\right]\\
   &=\frac{\partial tr\left[\Sigma_k^{-1}(X_i-\mu_k)(X_i-\mu_k)^T\right]}{\partial\Sigma_k^{-1}}\frac{\partial\Sigma_k^{-1}}{\partial\Sigma_k}\\
   &=-(X_i-\mu_k)(X_i-\mu_k)^T\Sigma_k^{-2}
   \end{aligned}
   \end{gathered}
   $$
   代入可得
   $$
   \frac{\partial L}{\partial \Sigma_k}=\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)}){1\over2}\left[(X_i-\mu_k)(X_i-\mu_k)^T-\Sigma_k\right]\Sigma_k^{-2}=0\tag{2}
   $$
   由式(1)得
   $$
   \mu_k^{(t+1)}=\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})X_i}{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}
   $$
   由式(2)得
   $$
   \Sigma_k^{(t+1)}=\frac{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})(X_i-\mu_k)(X_i-\mu_k)^T}{\sum_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}
   $$
### GMM算法步骤
> (1)初始化参数$\theta^{(0)}=(p_1,p_2,\cdots,p_k,\mu_1,\mu_2,\cdots,\mu_k,\Sigma_1,\Sigma_2,\cdots,\Sigma_k)$
> (2)E-Step：依据当前模型，计算后验概率
> $$
> P(Z_i=k|X_i,\theta^{(t)})=\frac{p_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k^{(t)})}{\sum_{k=1}^Kp_k^{(t)}N(X_i|\mu_k^{(t)},\Sigma_k)^{(t)}}\quad i=1,2,\cdots,N;k=1,2,\cdots,K
> $$
> (3)M-Step：计算下一轮迭代的参数
> $$
> \begin{gathered}
> p_k^{(t+1)}=\frac{\sum\limits_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}{N}\quad k=1,2,\cdots,K\\
> \mu_k^{(t+1)}=\frac{\sum\limits_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})X_i}{\sum\limits_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}\quad k=1,2,\cdots,K\\
> \Sigma_k^{(t+1)}=\frac{\sum\limits_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})(X_i-\mu_k)(X_i-\mu_k)^T}{\sum\limits_{i=1}^NP(Z_i=k|X_i,\theta^{(t)})}\quad k=1,2,\cdots,K
> \end{gathered}
> $$
> (4)重复步骤(2)、(3)，直至算法收敛