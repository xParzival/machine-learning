# 优化理论
## 无约束优化
设$f(\boldsymbol{x})$是实数域上的函数，考虑一个无约束优化问题
$$
\min_\boldsymbol{x}f(\boldsymbol{x})
$$
解析方法即求导是最直接的方法，但是在函数十分复杂时很难直接求得解析解，因此需要用到数值迭代算法，主要有以下几种求解方法
### 梯度下降法
梯度下降法(gradient descent)是求解无约束优化问题最常用的迭代算法
梯度下降法先选取一个初值$\boldsymbol{x}^{(0)}$，通过迭代不断更新$\boldsymbol{x}$来最小化$f(\boldsymbol{x})$函数值，最终收敛与最优解$\boldsymbol{x}^*$。因为函数值沿负梯度方向下降最快，因此迭代每一步都以负梯度方向更新$\boldsymbol{x}$
设第$t$次迭代值为$\boldsymbol{x}^{(t)}$，将$f(\boldsymbol{x})$在$\boldsymbol{x}^{(t)}$附近作一阶泰勒展开
$$
f(\boldsymbol{x})=f(\boldsymbol{x}^{(t)})+\nabla f(\boldsymbol{x}^
{(t)})\cdot(\boldsymbol{x}-\boldsymbol{x}^{(t)})
$$
其中$\nabla f(\boldsymbol{x}^{(t)})$为$f(\boldsymbol{x})$在$\boldsymbol{x}^{(t)}$处的梯度。$\boldsymbol{x}-\boldsymbol{x}^{(t)}$为一个很小的矢量，可令单位向量
$$
\boldsymbol{\nu}=\frac{\boldsymbol{x}-\boldsymbol{x}^{(t)}}{||\boldsymbol{x}-\boldsymbol{x}^{(t)}||}
$$
将$\boldsymbol{x}-\boldsymbol{x}^{(t)}$表示为
$$
\boldsymbol{x}-\boldsymbol{x}^{(t)}=\eta\boldsymbol{\nu},\quad\eta\gt0
$$
则有
$$
f(\boldsymbol{x})=f(\boldsymbol{x}^{(t)})+\nabla f(\boldsymbol{x}^{(t)})\cdot\eta\boldsymbol{\nu}
$$
我们希望在迭代后$f(x)$的值减小，而且减小的尽可能多，因此
$$
\begin{gathered}
f(\boldsymbol{x})-f(\boldsymbol{x}^{(t)})=\nabla f(\boldsymbol{x}^{(t)})\cdot\eta\boldsymbol{\nu}\lt0\\
\Rightarrow\nabla f(\boldsymbol{x}^{(t)})\cdot\boldsymbol{\nu}\lt0
\end{gathered}
$$
为了使$f(x)$的值减小的尽可能多，就要使$\nabla f(\boldsymbol{x}^{(t)})\cdot\boldsymbol{\nu}$尽可能小，显然当两个向量反向时乘积最小，也即$\boldsymbol{\nu}$在负梯度方向时能保证$f(x)$最大程度的减小
于是可得
$$
\boldsymbol{\nu}=-\frac{\nabla f(\boldsymbol{x}^{(t)})}{||\nabla f(\boldsymbol{x}^{(t)})||}
$$
代入$\boldsymbol{x}-\boldsymbol{x}^{(t)}=\eta\boldsymbol{\nu}$得
$$
\begin{gathered}
\boldsymbol{x}=\boldsymbol{x}^{(t)}-\eta\frac{\nabla f(\boldsymbol{x}^{(t)})}{||\nabla f(\boldsymbol{x}^{(t)})||}
\end{gathered}
$$
由于$||\nabla f(\boldsymbol{x}^{(t)})||$是个常数，于是最终的迭代公式可表示为
$$
\boldsymbol{x}^{(t+1)}=\boldsymbol{x}^{(t)}-\eta\nabla f(\boldsymbol{x}^{(t)})
$$
#### 应用
一般情况下，按上述理论的梯度下降法称为全量梯度下降法，因为在每一轮迭代中对所有样本都要计算一次梯度。这样做收敛速度快，结果精准，但是当样本量非常大时计算量很大，耗时反而会增加。于是在实际使用中，梯度下降法出现了很多变种
1. 随机梯度下降：每次迭代只对一个样本计算梯度并迭代更新。这样做计算速度非常快，但是精度会下降，一般收敛于最优值附近，且迭代次数会明显增加。因为到临近收敛时随机梯度下降法很难完全收敛到最优值，因此一般会让学习率在每次迭代之后有一定的减小，尽量逼近最优值
2. 批量梯度下降：是随机梯度下降的扩展，每次迭代不仅仅只用一个样本，而是随机选取一批样本。这样可以弥补随机梯度下降法精度不足的问题，同时又比全量梯度下降的速度更快

### 牛顿法
牛顿法也是常用的无约束优化问题迭代算法，收敛速度快，且比梯度下降法的精确度更高，但是计算更复杂
设第$t$次迭代值为$\boldsymbol{x}^{(t)}$，$H$是$f(x)$的Hessian矩阵。将$f(\boldsymbol{x})$在$\boldsymbol{x}^{(t)}$附近作二阶泰勒展开
$$
f(\boldsymbol{x})=f(\boldsymbol{x}^{(t)})+\nabla^\top f(\boldsymbol{x}^{(t)})(\boldsymbol{x}-\boldsymbol{x}^{(t)})+{1\over2}(\boldsymbol{x}-\boldsymbol{x}^{(t)})^\top H(\boldsymbol{x^{(t)}})(\boldsymbol{x}-\boldsymbol{x}^{(t)})
$$
为了使$f(\boldsymbol{x})$的值减小的尽可能快，则应该求使该二阶泰勒展开的值最小的$\boldsymbol{x}$，因此该二阶泰勒展开求导为零的点即为我们要找的$\boldsymbol{x}$，即
$$
\begin{gathered}
\nabla f(\boldsymbol{x})=\nabla f(\boldsymbol{x}^{(t)})+H(\boldsymbol{x^{(t)}})(\boldsymbol{x}-\boldsymbol{x}^{(t)})=0\\
\Rightarrow\boldsymbol{x}=\boldsymbol{x}^{(t)}-H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})
\end{gathered}
$$
因此得到迭代公式
$$
\boldsymbol{x}^{(t+1)}=\boldsymbol{x}^{(t)}-H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})
$$
可以看到，梯度下降法是用线性函数来近似代替目标函数，而牛顿法是用二次函数来代替目标函数，故牛顿法的收敛速度是更快的
牛顿法也是可以限制步长的。因为$-H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})$给定了$\boldsymbol{x}$的搜索方向，假设按一个步长$0\lt\eta\lt1$更新，则更新后
$$
\boldsymbol{x}=\boldsymbol{x}^{(t)}-\eta H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})
$$
显然这个$\boldsymbol{x}$仍然在我们做二阶泰勒展开的小区域之内，因此仍然满足二阶泰勒展开式的近似，故
$$
\begin{aligned}
f(\boldsymbol{x})-f(\boldsymbol{x}^{(t)})&=-\nabla^\top f(\boldsymbol{x}^{(t)})H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})+{1\over2}(-\eta H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)}))^\top H(\boldsymbol{x^{(t)}})(-\eta H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)}))\\
&=-\eta\nabla^\top f(\boldsymbol{x}^{(t)})H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})+{1\over2}\eta^2\nabla^\top f(\boldsymbol{x}^{(t)})H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})\\
&=\left({1\over2}\eta^2-\eta\right)\nabla^\top f(\boldsymbol{x}^{(t)})H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})
\end{aligned}
$$
如果$f(\boldsymbol{x})$在局部是凸函数，则Hessian矩阵在局部是正定的，于是$\nabla^\top f(\boldsymbol{x}^{(t)})H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})\gt0$，而$0\lt\eta\lt1$时${1\over2}\eta^2-\eta\lt0$，因此$f(\boldsymbol{x})-f(\boldsymbol{x}^{(t)})\lt0$，保证了$f(\boldsymbol{x})$的值在下降
根据上述分析，牛顿法在实际使用时也会限制步长$0\lt\eta\lt1$，迭代公式为
$$
\boldsymbol{x}^{(t+1)}=\boldsymbol{x}^{(t)}-\eta H^{-1}(\boldsymbol{x^{(t)}})\nabla f(\boldsymbol{x}^{(t)})
$$
牛顿法的局限性：
1. Hessian矩阵不一定可逆
2. Hessian矩阵规模很大时，会造成求逆计算十分困难，于是出现了改进算法拟牛顿法

### 拟牛顿法
因为计算Hessian矩阵的逆比较复杂，因此拟牛顿法采用了一个思想：考虑用一个矩阵$G_{t+1}$来近似代替$H^{-1}(\boldsymbol{x}^{(t)})$
由牛顿法的二阶泰勒展开求导可得
$$
\boldsymbol{x}^{(t+1)}-\boldsymbol{x}^{(t)}=H^{-1}(\boldsymbol{x}^{(t)})\left[\nabla f(\boldsymbol{x}^{(t+1)})-\nabla f(\boldsymbol{x}^{(t)})\right]
$$
令$\boldsymbol{\delta}_t=\boldsymbol{x}^{(t+1)}-\boldsymbol{x}^{(t)},\Delta\boldsymbol{g}_t=\nabla f(\boldsymbol{x}^{(t+1)})-\nabla f(\boldsymbol{x}^{(t)})$，则
$$
\boldsymbol{\delta}_t=H^{-1}(\boldsymbol{x}^{(t)})\Delta\boldsymbol{g}_t
$$
该式称为拟牛顿条件
如果要用矩阵$G_{t+1}$来近似代替$H^{-1}(\boldsymbol{x}^{(t)})$，那么$G_t$也要满足拟牛顿条件
$$
\boldsymbol{\delta}_t=G_{t+1}\Delta\boldsymbol{g}_t
$$
关于如何构造$G_{t+1}$，下面介绍两种算法
#### DFP算法
DFP算法核心思想是以迭代的方式来更新近似矩阵$G_{t+1}$，即
$$
G_{t+1}=G_t+\Delta G_t
$$
由于海塞矩阵是正定矩阵，所以可以将其变化量设为
$$
\Delta G_t=\alpha\boldsymbol{u}\boldsymbol{u}^\top+\beta\boldsymbol{v}\boldsymbol{v}^\top
$$
于是根据拟牛顿条件
$$
\begin{aligned}
\boldsymbol{\delta}_t&=(G_t+\alpha\boldsymbol{u}\boldsymbol{u}^\top+\beta\boldsymbol{v}\boldsymbol{v}^\top)\Delta\boldsymbol{g}_t\\
&=G_t\Delta\boldsymbol{g}_t+\alpha\boldsymbol{u}\boldsymbol{u}^\top\Delta\boldsymbol{g}_t+\beta\boldsymbol{v}\boldsymbol{v}^\top\Delta\boldsymbol{g}_t\\
&=G_t\Delta\boldsymbol{g}_t+\alpha\boldsymbol{u}^\top\Delta\boldsymbol{g}_t\boldsymbol{u}+\beta\boldsymbol{v}^\top\Delta\boldsymbol{g}_t\boldsymbol{v}
\end{aligned}
$$
因为$\alpha,\beta,\boldsymbol{u},\boldsymbol{v}$是我们构造的，于是可以构造满足以下条件的值和向量
$$
\begin{gathered}
\alpha\boldsymbol{u}^\top\Delta\boldsymbol{g}_t=1\quad\beta\boldsymbol{v}^\top\Delta\boldsymbol{g}_t=-1\\
\Rightarrow \alpha=\frac{1}{\boldsymbol{u}^\top\Delta\boldsymbol{g}_t}\quad\beta=-\frac{1}{\boldsymbol{v}^\top\Delta\boldsymbol{g}_t}
\end{gathered}
$$
于是有
$$
\begin{gathered}
\boldsymbol{\delta}_t=G_t\Delta\boldsymbol{g}_t+\boldsymbol{u}-\boldsymbol{v}\\
\Rightarrow\boldsymbol{\delta}_t-G_t\Delta\boldsymbol{g}_t=\boldsymbol{u}-\boldsymbol{v}
\end{gathered}
$$
则可令
$$
\boldsymbol{u}=\boldsymbol{\delta}_t\quad\boldsymbol{v}=G_t\Delta\boldsymbol{g}_t
$$
代入可求得
$$
\begin{gathered}
\alpha=\frac{1}{\boldsymbol{u}^\top\Delta\boldsymbol{g}_t}=\frac{1}{\boldsymbol{\delta}_t^\top\Delta\boldsymbol{g}_t}\\
\beta=-\frac{1}{\boldsymbol{v}^\top\Delta\boldsymbol{g}_t}=-\frac{1}{\Delta\boldsymbol{g}_t^\top G_t\Delta\boldsymbol{g}_t}
\end{gathered}
$$
代入初始式可得
$$
\Delta G_t=\frac{\boldsymbol{\delta}_t\boldsymbol{\delta}_t^\top}{\boldsymbol{\delta}_t^\top\Delta\boldsymbol{g}_t}-\frac{G_t\Delta\boldsymbol{g}_t\Delta\boldsymbol{g}_t^\top G_t}{\Delta\boldsymbol{g}_t^\top G_t\Delta\boldsymbol{g}_t}
$$
于是得到$G_t$的迭代公式
$$
G_{t+1}=G_t+\frac{\boldsymbol{\delta}_t\boldsymbol{\delta}_t^\top}{\boldsymbol{\delta}_t^\top\Delta\boldsymbol{g}_t}-\frac{G_t\Delta\boldsymbol{g}_t\Delta\boldsymbol{g}_t^\top G_t}{\Delta\boldsymbol{g}_t^\top G_t\Delta\boldsymbol{g}_t}
$$
### BFGS算法
DFS算法是用矩阵$G_{t+1}$来近似Hessian矩阵的逆，而BFGS算法是用矩阵$B_{t+1}$来近似Hessian矩阵本身
拟牛顿条件也可以写成
$$
\Delta\boldsymbol{g}_t=H(\boldsymbol{x}^{(t)})\boldsymbol{\delta}_t
$$
于是$B_{t+1}$要满足
$$
\Delta\boldsymbol{g}_t=B_{t+1}\boldsymbol{\delta}_t
$$
同DFS完全相同的方法可以推导出迭代公式
$$
B_{t+1}=B_t+\frac{\Delta\boldsymbol{g}_t\Delta\boldsymbol{g}_t^\top}{\Delta\boldsymbol{g}_t^\top\boldsymbol{\delta}_t}-\frac{B_t\boldsymbol{\delta}_t\boldsymbol{\delta}_t^\top B_t}{\boldsymbol{\delta}_t^\top B_t\boldsymbol{\delta}_t}
$$
## 拉格朗日对偶性
### 原始问题与对偶问题
考虑优化问题
$$
\begin{gathered}
\min_xf(x)\\
\begin{aligned}
s.t.\quad&c_i(x)\le0,\quad i=1,2,\cdots,k\\
&h_j(x)=0,\quad j=1,2,\cdots,l
\end{aligned}
\end{gathered}
$$
称这个最优化问题为原始问题
引入广义拉格朗日函数
$$
L(x,\alpha,\beta)=f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)
$$
其中$x=(x^{(1)},x^{(2)},\cdots,x^{(n)})^T\in\mathbb{R}^n$，$\alpha_i\ge0$
先将$L(x,\alpha,\beta)$看作$\alpha,\beta$的函数，那么可以得到一个关于$x$的函数
$$
\theta_P(x)=\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)
$$
假设存在$x$不满足某个约束条件，即存在$c_i(x)\gt0,h_j(x)\ne0$，显然此时若令$\alpha_i\to+\infty$，令$\beta_jh_j(x)\to+\infty$则有
$$
\theta_P(x)=\max_{\alpha,\beta:\alpha_i\ge0}\left[f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)\right]\to+\infty
$$
若$x$满足约束则有
$$
\theta_P(x)=\max_{\alpha,\beta:\alpha_i\ge0}\left[f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)\right]=f(x)
$$
完整写出来就是
$$
\theta_P(x)=\begin{cases}f(x),&x满足约束条件\\+\infty,&其他\end{cases}
$$
那么考虑如下问题
$$
\min_x\theta_P(x)=\min_x\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)
$$
显然此问题与原始问题完全等价，他们有相同的解。此问题称为广义拉格朗日函数的极小极大问题
与极小极大问题对应，有$L(x,\alpha,\beta)$函数的极大极小问题
$$
\max_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i\ge0}\min_xL(x,\alpha,\beta)
$$
对$\forall\alpha,\beta,x$有如下弱对偶性
$$
\begin{gathered}
\theta_D(\alpha,\beta)=\min_xL(x,\alpha,\beta)\le L(x,\alpha,\beta)\le\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)=\theta_P(x)\\
\Rightarrow\max_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)\le\min_x\theta_P(x)
\end{gathered}
$$
将$\max\limits_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)=\max\limits_{\alpha,\beta:\alpha_i\ge0}\min\limits_xL(x,\alpha,\beta)$称为原始问题的对偶问题
在数学上可以证明：若$f(x),c_i(x)$都是凸函数，$h_j(x)$是仿射函数，且不等式约束是严格可行的即存在$x$对所有$i$均有$c_i(x)\lt0$(Slater条件)，那么原始问题和对偶问题是等价的
### KKT条件
若$f(x),c_i(x)$都是凸函数，$h_j(x)$是仿射函数，且不等式约束是严格可行的(Slater条件)，对于原始问题和对偶问题，$x^*,\alpha^*,\beta^*$是它们的解的充分必要条件是$x^*,\alpha^*,\beta^*$满足以下KKT条件：
$$
\begin{gathered}
\nabla_xL(x^*,\alpha^*,\beta^*)=0\\
\alpha_i^*c_i(x^*)=0,\quad i=1,2,\cdots,k\\
c_i(x^*)\le0,\quad i=1,2,\cdots,k\\
\alpha_i^*\ge0,\quad i=1,2,\cdots,k\\
h_j(x^*)=0\quad j=1,2,\cdots,l
\end{gathered}
$$
其中$\alpha_i^*c_i(x^*)=0$称为对偶互补条件，若$\alpha_i^*\gt0$则有$c_i(x^*)=0$