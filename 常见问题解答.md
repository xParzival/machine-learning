## 类别变量处理
### 类别数量较少
一般使用one-hot编码、哑变量或effect编码处理。大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征通过编码，转化到多维特征，降低了空间和时间的效率
但我们知道对于决策树来说并不推荐使用编码，尤其当类别特征中类别个数很多的情况下，会存在以下问题：
1. 会产生样本切分不平衡问题，导致切分增益非常小（即浪费了这个特征）。使用 one-hot编码，意味着在每一个决策节点上只能使用one vs rest（例如是不是狗，是不是猫等）的切分方式。例如，动物类别切分后，会产生是否狗，是否猫等一系列特征，这一系列特征上只有少量样本为 1，大量样本为 0，这时候切分样本会产生不平衡，这意味着切分增益也会很小。较小的那个切分样本集，它占总样本的比例太小，无论增益多大，乘以该比例之后几乎可以忽略；较大的那个拆分样本集，它几乎就是原始的样本集，增益几乎为零。比较直观的理解就是不平衡的切分和不切分没有区别
2. 会影响决策树的学习。因为就算可以对这个类别特征进行切分，独热编码也会把数据切分到很多零散的小空间上。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习效果会变差

### 类别数量特别多
类别数目特别多时，如果还是用one-hot编码的方法，会造成维数爆炸。一般会使用压缩编码的方法，下面列举几种
1. 特征哈希
2. bin-counting
3. 深度学习中会使用一种embedding方法
4. 其他编码方式

# 类别不平衡
在很多业务场景下，分类任务会出现类别十分不平等的情况。也就是说，在数据集中，有一类含有的数据要远远多于其他类的数据（类别分布不平衡），此时如果直接训练会对模型效果有很大影响
考虑一个简单的例子，10万正样本与1000个负样本，正负样本比列为100：1，如果直接带入模型中去学习，每一次梯度下降如果使用全量样本，负样本的权重只有不到1/100，即使完全不学习负样本的信息，准确率也有超过99%，所以显然我们绝不能以准确率来衡量模型的效果。但是实践下面，我们其实也知道，即使用KS或者AUC来度量模型的表现，依然没法保证模型能将负样本很好的学习。而我们实际上需要得到一个分类器，既能对于正例有很高的准确率，同时又不会影响到负例的准确率
于是针对这个问题出现了一些解决办法
## 下探
所谓下探，就是对评分较低被拒绝的人进行放款，牺牲一部分收益，来积累坏样本，供后续模型学习，这是最直接解决风控场景样本不均衡的方法
这也是所有方法中最直接有效的。但是不是每一家公司都愿意承担这部分坏账的成本
此外随着业务开展，后续模型迭代的时候，使用的样本是有偏的，下探同样可以解决这个问题
## 半监督学习
### 拒绝推断
